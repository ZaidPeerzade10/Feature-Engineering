{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Questions"
      ],
      "metadata": {
        "id": "R5xrvu_EhkaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "   - A parameter is an internal variable of a machine learning model that is learned from the training data.\n",
        "   - It defines the relationship between input features and the predicted output.\n",
        "   - Examples include the weights in a linear regression model or the split points in a decision tree.\n",
        "   - Parameters are updated during training to minimize the model's error.\n",
        "\n",
        "2. What is correlation?What does negative correlation mean?\n",
        "   - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "   - It ranges from -1 to 1, where 1 indicates a perfect positive relationship, -1 indicates a perfect negative relationship, and 0 means no correlation.\n",
        "   - It's commonly used in data analysis to identify linear relationships.\n",
        "   - Correlation doesn't imply causation.\n",
        "   - Negative correlation means that as one variable increases, the other decreases.\n",
        "   - The correlation value lies between -1 and 0. For example, if time spent watching TV increases and academic performance decreases, they have a negative correlation.\n",
        "   - It shows an inverse relationship.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "   - Machine Learning is a subset of AI that allows systems to learn patterns from data and make decisions without being explicitly programmed.\n",
        "   - The main components are data, features, a model, a learning algorithm, and an evaluation metric.\n",
        "   - These components work together to train the model to make predictions.\n",
        "   - The goal is to minimize error and generalize well to unseen data.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "   - The loss value measures the difference between the predicted output and the actual output.\n",
        "   - A lower loss indicates better performance of the model.\n",
        "   - It guides the optimization process to adjust parameters and improve accuracy.\n",
        "   - Monitoring loss helps detect overfitting or underfitting.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "   - Continuous variables are numerical values that can take any value within a range (e.g., height, temperature).\n",
        "   - Categorical variables represent discrete groups or categories (e.g., gender, color).\n",
        "   - Continuous variables are usually measured, while categorical variables are labeled.\n",
        "   - Different preprocessing techniques are applied to each type in ML.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "   - Categorical variables are typically converted into numerical formats using encoding methods.\n",
        "   - Common techniques include label encoding, one-hot encoding, and ordinal encoding.\n",
        "   - One-hot encoding is used when categories are not ordinal, while label encoding is suitable for tree-based models.\n",
        "   - Proper encoding helps algorithms interpret categorical data.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "   - Training a dataset involves using it to teach the model how to make predictions.\n",
        "   - Testing evaluates the model's performance on unseen data to check its generalization ability.\n",
        "   - The training set is used to fit the model, and the test set assesses how well it performs.\n",
        "   - This split helps avoid overfitting.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a module in Scikit-learn that provides functions for scaling, transforming, and encoding features.\n",
        "   - It helps standardize or normalize input data for better model performance.\n",
        "   - It includes methods like StandardScaler, MinMaxScaler, and OneHotEncoder.\n",
        "   - These transformations prepare raw data for machine learning.\n",
        "\n",
        "9. What is a Test set?How do we split data for model fitting (training and testing) in Python?\n",
        "   - A test set is a portion of the dataset used to evaluate the performance of a trained model.\n",
        "   - It simulates how the model will perform on real-world unseen data. The model does not learn from this set; it only predicts outcomes.\n",
        "   - It's crucial for assessing model generalization.\n",
        "   In Python, the train_test_split() function from sklearn.model_selection is used to split the data.\n",
        "   - You specify the test size (e.g., 0.2 for 20%) and optionally use a random state for reproducibility.\n",
        "   - It returns four datasets: X_train, X_test, y_train, and y_test.\n",
        "   - This ensures that the model is trained and evaluated separately.\n",
        "\n",
        "10. How do you approach a Machine Learning problem?\n",
        "   - Start by understanding the problem and collecting relevant data.\n",
        "   - Then, perform exploratory data analysis (EDA), preprocessing, and feature engineering.\n",
        "   - After that, select and train a model, evaluate it using appropriate metrics, and tune hyperparameters.\n",
        "   - Finally, validate and deploy the model.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "   - EDA helps in understanding the structure, patterns, and anomalies in the dataset.\n",
        "   - It identifies missing values, outliers, and relationships between variables.\n",
        "   - This insight guides data cleaning and feature selection.\n",
        "   - EDA ensures better model performance and avoids issues during training.\n",
        "\n",
        "12. What is correlation?\n",
        "   - Correlation is a measure of how two variables move in relation to each other.\n",
        "   - Positive correlation means they increase together; negative correlation means one increases while the other decreases.\n",
        "   - It is useful for identifying linear relationships in EDA.\n",
        "   - It does not imply causation.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "   - Negative correlation implies that an increase in one variable results in a decrease in the other.\n",
        "   - The correlation value is less than 0. For example, if the number of hours spent exercising increases and weight decreases, the variables are negatively correlated.\n",
        "   - It's an inverse relationship.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "   - You can use the .corr() method on a Pandas DataFrame to compute correlation coefficients.\n",
        "   - It returns a correlation matrix showing relationships between all numeric features.\n",
        "   - You can also visualize it using a heatmap with Seaborn (sns.heatmap()).\n",
        "   - This helps identify strong or weak linear dependencies.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "   - Causation means one variable directly affects another, while correlation only shows a relationship.\n",
        "   - For example, ice cream sales and drowning deaths may be correlated, but one does not cause the other; the underlying cause is hot weather.\n",
        "   - Correlation does not imply a cause-effect link.\n",
        "   - Causation requires experimental or controlled study.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   - An optimizer adjusts model parameters to minimize loss during training.\n",
        "   - Common types include SGD (Stochastic Gradient Descent), Adam, and RMSProp.\n",
        "   - SGD updates weights based on the gradient of loss, while Adam combines momentum and adaptive learning rates for faster convergence.\n",
        "   - For example, optimizer = Adam(lr=0.001) in Keras optimizes the model during backpropagation.\n",
        "\n",
        "17. What is sklearn.linear_model?\n",
        "   - sklearn.linear_model is a Scikit-learn module for implementing linear models like Linear Regression, Logistic Regression, and Ridge Regression.\n",
        "   - It provides classes for training models on linearly related data.\n",
        "   - For example, LinearRegression() fits a line to predict continuous values.\n",
        "   - It supports both regression and classification.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "   - model.fit() trains the model using the provided input (X) and target (y) data.\n",
        "   - It learns the relationship between features and labels.\n",
        "   - The required arguments are the training features X_train and target labels y_train.\n",
        "   - Optionally, you can specify parameters like epochs, batch size (in deep learning), or sample weights.\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "   - model.predict() generates output predictions for the given input data.\n",
        "   - It takes new input data (e.g., X_test) and uses the trained model to estimate the target values.\n",
        "   - This is used for testing or deploying the model.\n",
        "   - It helps in evaluating how well the model generalizes.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "   - Continuous variables are numeric and can take an infinite number of values within a range (e.g., age, salary).\n",
        "   - Categorical variables represent distinct groups or categories (e.g., city, product type).\n",
        "   - Each type requires different preprocessing for machine learning models.\n",
        "   - Algorithms may interpret them differently.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "   - Feature scaling transforms features to be on a similar scale to improve model performance.\n",
        "   - It prevents features with large magnitudes from dominating the model.\n",
        "   - It's essential for algorithms like KNN, SVM, and gradient descent-based models.\n",
        "   - Common methods include normalization and standardization.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "   - In Python, scaling is done using StandardScaler or MinMaxScaler from sklearn.preprocessing.\n",
        "   - StandardScaler standardizes features to have zero mean and unit variance.\n",
        "   - MinMaxScaler scales data to a fixed range (usually 0 to 1).\n",
        "   - Fit the scaler on training data and transform both training and test sets.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a Scikit-learn module that provides tools to transform input data before training.\n",
        "   - It includes functions for scaling, encoding, binarization, and generating polynomial features.\n",
        "   - These transformations improve data quality and model performance.\n",
        "   - It ensures consistency and prepares data for model consumption.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "   - Use train_test_split() from sklearn.model_selection to divide data.\n",
        "   - Pass in features, labels, and specify test_size and random_state for reproducibility.\n",
        "   - It returns training and testing sets: X_train, X_test, y_train, y_test.\n",
        "   - This helps validate the model properly.\n",
        "\n",
        "25. Explain data encoding?\n",
        "   - Data encoding converts categorical values into numeric form for model compatibility.\n",
        "   - Techniques include one-hot encoding, label encoding, and ordinal encoding.\n",
        "   - Encoding helps machine learning algorithms interpret non-numeric data correctly.\n",
        "   - It's a crucial preprocessing step before model training."
      ],
      "metadata": {
        "id": "DxJUEjBjK-82"
      }
    }
  ]
}